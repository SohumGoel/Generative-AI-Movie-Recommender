{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSDU147nW2Jw",
        "outputId": "e8763169-45ab-48c0-9e79-e5017328bd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! kaggle datasets download tmdb/tmdb-movie-metadata\n",
        "# ! unzip tmdb-movie-metadata.zip\n",
        "# !pip install openai httpx==0.27.2 --force-reinstall --quiet\n",
        "# !pip install clickhouse-connect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Yapldxlsdo",
        "outputId": "a7c97ac2-789d-49ae-bb31-e9a99201738e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting clickhouse-connect\n",
            "  Downloading clickhouse_connect-0.8.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect) (2024.8.30)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect) (2.2.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect) (2024.2)\n",
            "Collecting zstandard (from clickhouse-connect)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting lz4 (from clickhouse-connect)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Downloading clickhouse_connect-0.8.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.5/978.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard, lz4, clickhouse-connect\n",
            "Successfully installed clickhouse-connect-0.8.9 lz4-4.3.3 zstandard-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "UXwMVCoJrlPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "movies = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/movie/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/movie/tmdb_5000_credits.csv')"
      ],
      "metadata": {
        "id": "JYozK3fBl32t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the 'movie_id' column in 'credits' to 'id'\n",
        "credits.rename(columns = {'movie_id':'id'}, inplace = True)\n",
        "df = credits.merge(movies, on = 'id')\n",
        "# Remove rows with missing values in the 'overview' column\n",
        "df.dropna(subset = ['overview'], inplace=True)\n",
        "# Select only most relevant columns for the final DataFrame\n",
        "df = df[['id', 'title_x', 'genres', 'overview', 'cast', 'crew']]"
      ],
      "metadata": {
        "id": "8HNxhqb5m7cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def generate_corpus(row):\n",
        "    overview, genre, cast, crew = row['overview'], row['genres'], row['cast'], row['crew']\n",
        "    corpus = \"\"\n",
        "    genre = ','.join([i['name'] for i in eval(genre)])\n",
        "    cast = ','.join([i['name'] for i in eval(cast)[:3]])\n",
        "    crew = ','.join(list(set([i['name'] for i in eval(crew) if i['job'] == 'Director' or i['job'] == 'Producer'])))\n",
        "    corpus += overview + \" \" + genre + \" \" + cast + \" \" + crew\n",
        "    return pd.Series([corpus, crew, cast, genre], index=['corpus', 'crew', 'cast', 'genres'])\n",
        "\n",
        "df[['corpus', 'crew', 'cast', 'genres']] = df.apply(generate_corpus, axis=1)"
      ],
      "metadata": {
        "id": "U_u3OvipnrW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai-key')\n",
        "\n",
        "def get_embeddings(text):\n",
        "    response = openai.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=text\n",
        "    )\n",
        "    return response.data\n",
        "\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(5):\n",
        "    start_idx = i * 1000\n",
        "    end_idx = (i + 1) * 1000\n",
        "    print(f\"Processing entries from {start_idx} to {end_idx}\")\n",
        "\n",
        "    chunk = df[start_idx:end_idx]\n",
        "    chunk[\"corpus\"] = chunk[\"corpus\"].astype(str)  # Ensure all entries are strings\n",
        "\n",
        "    try:\n",
        "      embeddings = get_embeddings(chunk[\"corpus\"].tolist())\n",
        "      vectors = [embedding.embedding for embedding in embeddings]\n",
        "      all_embeddings.extend(vectors)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing entries {start_idx}-{end_idx}: {e}\")\n",
        "        break\n",
        "\n",
        "# Add embeddings back to the DataFrame\n",
        "embeddings_array = np.array(all_embeddings)\n",
        "df['embeddings'] = pd.Series(list(embeddings_array))\n",
        "print(df[\"embeddings\"].head())\n",
        "print(df[\"embeddings\"].apply(type).value_counts())\n",
        "df = df[df[\"embeddings\"].apply(lambda x: isinstance(x, (list, np.ndarray)) and all(isinstance(i, (float, np.float32)) for i in x))]\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kjXwhAuSn7IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clickhouse_connect\n",
        "\n",
        "client = clickhouse_connect.get_client(\n",
        "    host=userdata.get('hostname'),\n",
        "    port=443,\n",
        "    username=userdata.get('usename'),\n",
        "    password=userdata.get('scalepass')\n",
        ")"
      ],
      "metadata": {
        "id": "0Rn66E1h4W8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  client.command(\"\"\"\n",
        "    CREATE TABLE default.movies (\n",
        "        id Int64,\n",
        "        title_x String,\n",
        "        genres String,\n",
        "        overview String,\n",
        "        cast String,\n",
        "        crew String,\n",
        "        corpus String,\n",
        "        embeddings Array(Float32),\n",
        "        CONSTRAINT check_data_length CHECK length(embeddings) = 1536\n",
        "    ) ENGINE = MergeTree()\n",
        "    ORDER BY id\n",
        "    \"\"\")\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "LD9VVjaC6JOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_batches = len(df) // batch_size\n",
        "\n",
        "\n",
        "for i in range(num_batches):\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    batch_data = df[start_idx:end_idx]\n",
        "\n",
        "    client.insert(\"default.movies\", batch_data.to_records(index=False).tolist(), column_names=batch_data.columns.tolist())\n",
        "    print(f\"Batch {i+1}/{num_batches} inserted.\")\n",
        "\n",
        "client.command(\"\"\"\n",
        "ALTER TABLE default.movies\n",
        "    ADD VECTOR INDEX vector_index embeddings\n",
        "    TYPE MSTG\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yuLGSrQK6gMM",
        "outputId": "55d3e50a-0c35-45b5-918f-7165539884ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1/47 inserted.\n",
            "Batch 2/47 inserted.\n",
            "Batch 3/47 inserted.\n",
            "Batch 4/47 inserted.\n",
            "Batch 5/47 inserted.\n",
            "Batch 6/47 inserted.\n",
            "Batch 7/47 inserted.\n",
            "Batch 8/47 inserted.\n",
            "Batch 9/47 inserted.\n",
            "Batch 10/47 inserted.\n",
            "Batch 11/47 inserted.\n",
            "Batch 12/47 inserted.\n",
            "Batch 13/47 inserted.\n",
            "Batch 14/47 inserted.\n",
            "Batch 15/47 inserted.\n",
            "Batch 16/47 inserted.\n",
            "Batch 17/47 inserted.\n",
            "Batch 18/47 inserted.\n",
            "Batch 19/47 inserted.\n",
            "Batch 20/47 inserted.\n",
            "Batch 21/47 inserted.\n",
            "Batch 22/47 inserted.\n",
            "Batch 23/47 inserted.\n",
            "Batch 24/47 inserted.\n",
            "Batch 25/47 inserted.\n",
            "Batch 26/47 inserted.\n",
            "Batch 27/47 inserted.\n",
            "Batch 28/47 inserted.\n",
            "Batch 29/47 inserted.\n",
            "Batch 30/47 inserted.\n",
            "Batch 31/47 inserted.\n",
            "Batch 32/47 inserted.\n",
            "Batch 33/47 inserted.\n",
            "Batch 34/47 inserted.\n",
            "Batch 35/47 inserted.\n",
            "Batch 36/47 inserted.\n",
            "Batch 37/47 inserted.\n",
            "Batch 38/47 inserted.\n",
            "Batch 39/47 inserted.\n",
            "Batch 40/47 inserted.\n",
            "Batch 41/47 inserted.\n",
            "Batch 42/47 inserted.\n",
            "Batch 43/47 inserted.\n",
            "Batch 44/47 inserted.\n",
            "Batch 45/47 inserted.\n",
            "Batch 46/47 inserted.\n",
            "Batch 47/47 inserted.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', 'chi-msc-4aa38d18-msc-4aa38d18-0-0', 'OK', '0', '0']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "genres = []\n",
        "\n",
        "for i in range(3):\n",
        "    genre = input(\"Enter a genre: \")\n",
        "    genres.append(genre)\n",
        "\n",
        "genre_string = ', '.join(genres)\n",
        "genre_embeddings=get_embeddings(genre_string)\n",
        "embeddings=genre_embeddings[0].embedding\n",
        "embeddings = np.array(genre_embeddings[0].embedding)  # Convert to numpy array\n",
        "\n",
        "decay_factor = 0.9  # Adjust as needed for exponential decay\n",
        "\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    results = client.query(f\"\"\"\n",
        "        SELECT title_x, genres,\n",
        "        distance(embeddings, {embeddings.tolist()}) as dist FROM default.movies ORDER BY dist LIMIT 10\n",
        "    \"\"\")\n",
        "\n",
        "    # Display the results\n",
        "    print(\"Recommended Movies:\")\n",
        "    movies = []\n",
        "    for row in results.named_results():\n",
        "        print(row[\"title_x\"])\n",
        "        movies.append(row['title_x'])\n",
        "\n",
        "    # Ask the user to select a movie\n",
        "    selection = int(input(\"Select a movie (or enter 0 to exit): \"))\n",
        "    if selection == 0:\n",
        "        break\n",
        "    selected_movie = movies[selection - 1]\n",
        "\n",
        "    # Get the embeddings of the selected movie title\n",
        "    selected_movie_embeddings = get_embeddings(selected_movie)[0].embedding\n",
        "    selected_movie_embeddings_array = np.array(selected_movie_embeddings)\n",
        "\n",
        "    # Apply exponential decay and update combined_embeddings\n",
        "    embeddings = decay_factor * embeddings + (1 - decay_factor) * selected_movie_embeddings_array\n",
        "\n",
        "    # Normalize the combined embeddings\n",
        "    embeddings = embeddings / np.linalg.norm(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-obiCzEW7-nl",
        "outputId": "fbcfd28b-c2ef-45b1-91bc-d21ef0610c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommended Movies:\n",
            "Special\n",
            "Krampus\n",
            "Creepshow\n",
            "On the Waterfront\n",
            "Deadline - U.S.A.\n",
            "Top Hat\n",
            "The Crazies\n",
            "Warm Bodies\n",
            "Margaret\n",
            "Running Forever\n",
            "Select a movie (or enter 0 to exit): 0\n"
          ]
        }
      ]
    }
  ]
}